{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Agents are connected but have their own states. Only the final responses are appended to global state\n",
    "\n",
    "<img src=\"../../resources/images/multi_agent_supervisor.png\" alt=\"Multi Agent Supervisor\" height=\"300\" width=\"300\">\n",
    "\n",
    "Agents are independent LangChain agents. This means they have their own individual prompt, LLM, and tools."
   ],
   "id": "bd92306529b510c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:49:12.831111Z",
     "start_time": "2025-05-14T13:49:12.039967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "from src.langchain.lg_workflow import *\n",
    "from src.langchain.agents.framenet_agent import *\n",
    "config = {\"configurable\" : {\"thread_id\" : 1}}"
   ],
   "id": "3442cb04371686b8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:47:02.843597Z",
     "start_time": "2025-05-14T13:46:46.332764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fnr = framenet_tool.invoke({'instruction':'pick up the cup'})\n",
    "fnr"
   ],
   "id": "3bd3077ecf3cf38a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE FRAMENET TOOL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"cup\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the cup\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:37:21.038687Z",
     "start_time": "2025-05-14T13:37:00.038597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 plus 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "d1d826be26eb7678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: mather\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE ADD TOOL\n",
      "(('mather:451715db-5fa9-0259-8b92-e3776d81c411',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-14T13:37:12.709533427Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11444325153, 'load_duration': 10142083, 'prompt_eval_count': 227, 'prompt_eval_duration': 2376090133, 'eval_count': 140, 'eval_duration': 9049944467, 'model_name': 'qwen3:4b'}, id='run--7b927f38-5079-42f9-a3ff-57e9d90f48f3-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': '4f182ee9-a4bd-49d4-a779-a184189a58e0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 227, 'output_tokens': 140, 'total_tokens': 367})]}})\n",
      "----\n",
      "(('mather:451715db-5fa9-0259-8b92-e3776d81c411',), {'tools': {'messages': [ToolMessage(content='4.0', name='add', id='35693c29-3ec9-4b4c-8641-aa20412d547f', tool_call_id='4f182ee9-a4bd-49d4-a779-a184189a58e0')]}})\n",
      "----\n",
      "(('mather:451715db-5fa9-0259-8b92-e3776d81c411',), {'agent': {'messages': [AIMessage(content='<think>\\nOkay, the user asked \"what is 2 plus 2\". I used the add function with a=2 and b=2. The tool response was 4.0. So the answer should be 4. I need to present it clearly. Let me check if there\\'s any other step, but since the user just wants the result, I can directly state that 2 plus 2 equals 4.\\n</think>\\n\\nThe result of 2 plus 2 is 4.', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-14T13:37:20.090154063Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7377584910, 'load_duration': 9552784, 'prompt_eval_count': 265, 'prompt_eval_duration': 595491085, 'eval_count': 102, 'eval_duration': 6761110636, 'model_name': 'qwen3:4b'}, id='run--d3e27e86-3d59-4a3a-a64c-31e3a3a1820f-0', usage_metadata={'input_tokens': 265, 'output_tokens': 102, 'total_tokens': 367})]}})\n",
      "----\n",
      "((), {'mather': {'messages': [HumanMessage(content='<think>\\nOkay, the user asked \"what is 2 plus 2\". I used the add function with a=2 and b=2. The tool response was 4.0. So the answer should be 4. I need to present it clearly. Let me check if there\\'s any other step, but since the user just wants the result, I can directly state that 2 plus 2 equals 4.\\n</think>\\n\\nThe result of 2 plus 2 is 4.', additional_kwargs={}, response_metadata={}, name='mather')]}})\n",
      "----\n",
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:22:49.578738Z",
     "start_time": "2025-05-14T09:22:49.569221Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config)",
   "id": "5fe2bd5f0a565fd8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='what is 2 plus 2', additional_kwargs={}, response_metadata={}, id='dc8c3d7a-8957-4a0d-a4f1-2ac8357f33c7'), HumanMessage(content='<think>\\nOkay, the user asked \"what is 2 plus 2\". I need to use the add function since that\\'s for adding numbers. The parameters are a and b, both numbers. So I\\'ll call add with a=2 and b=2. The response from the tool was 4.0, which makes sense. I should present that as the answer clearly.\\n</think>\\n\\nThe result of 2 plus 2 is 4.0.', additional_kwargs={}, response_metadata={}, name='mather', id='74bc0f36-7701-45f2-85c6-e535f3c894b5')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030a4e-32de-6ce1-8003-df93608a74e6'}}, metadata={'source': 'loop', 'writes': {'supervisor': None}, 'step': 3, 'parents': {}, 'thread_id': 1}, created_at='2025-05-14T09:21:59.269232+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030a4e-2918-65dd-8002-f0a778025930'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:50:01.752345Z",
     "start_time": "2025-05-14T13:49:23.282069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"framenet representation of the action pick up the blue mug\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "5c21296a78044bb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE FRAMENET TOOL(('framenet:4bf7d798-48d0-cac5-fd0d-3ec8751b5eab',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-14T13:49:27.3412604Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3217029803, 'load_duration': 8288274, 'prompt_eval_count': 188, 'prompt_eval_duration': 1199045476, 'eval_count': 32, 'eval_duration': 2004830480, 'model_name': 'qwen3:4b'}, id='run--3d05272f-6302-493d-8209-494b0d084677-0', tool_calls=[{'name': 'framenet_tool', 'args': {'__arg1': 'pick up the blue mug'}, 'id': 'c9893131-9396-4a10-a5f5-79d987c1c7fa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 188, 'output_tokens': 32, 'total_tokens': 220})]}})\n",
      "----\n",
      "\n",
      "(('framenet:4bf7d798-48d0-cac5-fd0d-3ec8751b5eab',), {'tools': {'messages': [ToolMessage(content='\"{\\\\n  \\\\\"framenet\\\\\": \\\\\"picking_up\\\\\",\\\\n  \\\\\"frame\\\\\": \\\\\"Getting\\\\\",\\\\n  \\\\\"lexical-unit\\\\\": \\\\\"pick up.v\\\\\",\\\\n  \\\\\"core\\\\\": {\\\\n    \\\\\"agent\\\\\": \\\\\"robot\\\\\",\\\\n    \\\\\"theme_patient\\\\\": \\\\\"blue mug\\\\\",\\\\n    \\\\\"instrument\\\\\": \\\\\"robot gripper\\\\\",\\\\n    \\\\\"source\\\\\": \\\\\"\\\\\",\\\\n    \\\\\"goal\\\\\": \\\\\"\\\\\",\\\\n    \\\\\"result\\\\\": \\\\\"robot has the blue mug\\\\\"\\\\n  },\\\\n  \\\\\"peripheral\\\\\": {\\\\n    \\\\\"location\\\\\": \\\\\"kitchen workspace\\\\\",\\\\n    \\\\\"manner\\\\\": \\\\\"gently\\\\\",\\\\n    \\\\\"direction\\\\\": \\\\\"upward\\\\\",\\\\n    \\\\\"time\\\\\": \\\\\"during cleanup phase\\\\\",\\\\n    \\\\\"quantity\\\\\": \\\\\"one item\\\\\",\\\\n    \\\\\"portion\\\\\": \\\\\"\\\\\"\\\\n  }\\\\n}\"', name='framenet_tool', id='1838edcd-2622-4edc-ad96-96bdea8a72fc', tool_call_id='c9893131-9396-4a10-a5f5-79d987c1c7fa')]}})\n",
      "----\n",
      "(('framenet:4bf7d798-48d0-cac5-fd0d-3ec8751b5eab',), {'agent': {'messages': [AIMessage(content='<think>\\n\\n</think>\\n\\nThe frame net representation of the action \"pick up the blue mug\" is as follows:\\n\\n```\\n{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"blue mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the blue mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}\\n```', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-14T13:50:01.050468892Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16801759518, 'load_duration': 15448907, 'prompt_eval_count': 395, 'prompt_eval_duration': 5926848605, 'eval_count': 165, 'eval_duration': 10841632001, 'model_name': 'qwen3:4b'}, id='run--43f96dae-0186-40ef-9a58-00fbebd158d6-0', usage_metadata={'input_tokens': 395, 'output_tokens': 165, 'total_tokens': 560})]}})\n",
      "----\n",
      "((), {'framenet': {'messages': [HumanMessage(content='<think>\\n\\n</think>\\n\\nThe frame net representation of the action \"pick up the blue mug\" is as follows:\\n\\n```\\n{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"blue mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the blue mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}\\n```', additional_kwargs={}, response_metadata={}, name='framenet')]}})\n",
      "----\n",
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:50:01.773632Z",
     "start_time": "2025-05-14T13:50:01.767614Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config)",
   "id": "bd7982a94a5903db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='framenet representation of the action pick up the blue mug', additional_kwargs={}, response_metadata={}, id='0799e26c-ec5e-4192-a572-da7977e29718'), HumanMessage(content='<think>\\n\\n</think>\\n\\nThe frame net representation of the action \"pick up the blue mug\" is as follows:\\n\\n```\\n{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"blue mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the blue mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}\\n```', additional_kwargs={}, response_metadata={}, name='framenet', id='27431628-c099-4b72-8ef7-bc18553b76f5')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030ca5-515c-65ef-8003-eefaac747835'}}, metadata={'source': 'loop', 'writes': {'supervisor': None}, 'step': 3, 'parents': {}, 'thread_id': 1}, created_at='2025-05-14T13:50:01.750255+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030ca5-4ab5-6b38-8002-f49f27090fab'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:38:32.597054Z",
     "start_time": "2025-05-14T09:36:12.227145Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the cup from the fridge')]}, config=config)['messages'][0].content",
   "id": "9dffdd1545ffc558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "INSIDE FRAMENET TOOL\n",
      "Next Worker: FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'framenet representation of the action pick up the cup from the fridge'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:38:38.977802Z",
     "start_time": "2025-05-14T09:38:38.971929Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config=config)",
   "id": "b827a45b1d8ad47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='framenet representation of the action pick up the cup from the fridge', additional_kwargs={}, response_metadata={}, id='f483963d-5427-4948-a7e7-58fb2ff3e523'), HumanMessage(content='<think>\\nOkay, the user asked for the FrameNet representation of \"pick up the cup from the fridge.\" I called the framenet_tool with that phrase. The response came back with a structured JSON. Let me parse this.\\n\\nThe main action is \"picking_up\" under the \"Getting\" frame. The lexical unit is \"pick up.v.\" The core elements have the agent as \"robot,\" theme_patient as \"cup,\" instrument as \"robot gripper,\" source as \"fridge.\" The result is the robot having the cup. Peripheral details include location, manner, direction, time, etc.\\n\\nI need to present this in a clear way. Maybe list the main components first, then the peripheral. Make sure to highlight the key elements like agent, theme, instrument, source. Also mention the result. The peripheral info adds context, so include that too. Keep it concise but informative. Avoid jargon so it\\'s easy to understand. Check if all parts of the original query are addressed. The user might be analyzing the action\\'s components, so clarity is key. Alright, time to put it all together.\\n</think>\\n\\nThe FrameNet representation for \"pick up the cup from the fridge\" is as follows:\\n\\n**Frame**: `Getting`  \\n**Lexical Unit**: `pick up.v`  \\n**Core Elements**:  \\n- **Agent**: robot  \\n- **Theme/Patient**: cup  \\n- **Instrument**: robot gripper  \\n- **Source**: fridge  \\n- **Result**: robot has the cup  \\n\\n**Peripheral Details**:  \\n- **Location**: kitchen workspace  \\n- **Manner**: gently  \\n- **Direction**: upward  \\n- **Time**: during cleanup phase  \\n- **Quantity**: one item  \\n\\nThis structure captures the action\\'s semantic roles and contextual modifiers.', additional_kwargs={}, response_metadata={}, name='framenet', id='397914a8-26b4-4d3f-ba9d-047f68d0eb52')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030a73-33ed-6f68-8003-b0707d666ede'}}, metadata={'source': 'loop', 'writes': {'supervisor': None}, 'step': 3, 'parents': {}, 'thread_id': 1}, created_at='2025-05-14T09:38:32.591532+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f030a73-2c34-6949-8002-288047a13200'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:39:10.388023Z",
     "start_time": "2025-05-14T09:39:10.380490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# graph.get_state(config=config).values['messages'][-1].content\n",
    "framenet_answers"
   ],
   "id": "accb1841acaf3fa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"cup\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"fridge\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the cup\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:07:01.087586Z",
     "start_time": "2025-05-13T14:06:44.972079Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the mug from the fridge')]})['messages'][1].content",
   "id": "5547cddfa73627e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "INSIDE FRAMENET TOOL\n",
      "Next Worker: FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user asked for the FrameNet representation of \"pick up the mug from the fridge.\" I called the framenet_tool with that instruction. The response came back with the frame \"Getting\" and the lexical unit \"pick up.v\". The core elements have agent as robot, theme_patient as mug, instrument as robot gripper, source as fridge, and the result is the robot having the mug. Peripheral details include location, manner, direction, etc.\\n\\nNow, I need to present this information as the final answer. The user probably wants a clear, structured output without extra explanations. Let me format the response using the FrameNet elements provided. Make sure to include all the core and peripheral elements as listed. Use the exact terms from the tool\\'s response. Avoid any markdown and just present the data in a readable way. Check if all the keys and values are correctly transcribed. Alright, that should do it.\\n</think>\\n\\n{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"fridge\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen\",\\n    \"manner\": \"carefully\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during retrieval\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T08:25:56.174008Z",
     "start_time": "2025-05-14T08:25:56.133820Z"
    }
   },
   "cell_type": "code",
   "source": "framenet_agent.invoke({'messages': [HumanMessage(content='pick up the mug from the sink')]})",
   "id": "1b4fdcbaed17b4e8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mframenet_agent\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpick up the mug from the sink\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/hometesting/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2823\u001B[39m, in \u001B[36mPregel.invoke\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001B[39m\n\u001B[32m   2820\u001B[39m chunks: \u001B[38;5;28mlist\u001B[39m[Union[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any], Any]] = []\n\u001B[32m   2821\u001B[39m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] = []\n\u001B[32m-> \u001B[39m\u001B[32m2823\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2824\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   2825\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2826\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2827\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2828\u001B[39m \u001B[43m    \u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2829\u001B[39m \u001B[43m    \u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2830\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_during\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheckpoint_during\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2831\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2832\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2833\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   2834\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvalues\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[32m   2835\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2836\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   2837\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mints\u001B[49m\u001B[43m \u001B[49m\u001B[43m:=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINTERRUPT\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[32m   2838\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/hometesting/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2372\u001B[39m, in \u001B[36mPregel.stream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2356\u001B[39m run_manager = callback_manager.on_chain_start(\n\u001B[32m   2357\u001B[39m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   2358\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2359\u001B[39m     name=config.get(\u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.get_name()),\n\u001B[32m   2360\u001B[39m     run_id=config.get(\u001B[33m\"\u001B[39m\u001B[33mrun_id\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   2361\u001B[39m )\n\u001B[32m   2362\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2363\u001B[39m     \u001B[38;5;66;03m# assign defaults\u001B[39;00m\n\u001B[32m   2364\u001B[39m     (\n\u001B[32m   2365\u001B[39m         debug,\n\u001B[32m   2366\u001B[39m         stream_modes,\n\u001B[32m   2367\u001B[39m         output_keys,\n\u001B[32m   2368\u001B[39m         interrupt_before_,\n\u001B[32m   2369\u001B[39m         interrupt_after_,\n\u001B[32m   2370\u001B[39m         checkpointer,\n\u001B[32m   2371\u001B[39m         store,\n\u001B[32m-> \u001B[39m\u001B[32m2372\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_defaults\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2373\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2374\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2375\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2376\u001B[39m \u001B[43m        \u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2377\u001B[39m \u001B[43m        \u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2378\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2379\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2380\u001B[39m     \u001B[38;5;66;03m# set up subgraph checkpointing\u001B[39;00m\n\u001B[32m   2381\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.checkpointer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/hometesting/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2185\u001B[39m, in \u001B[36mPregel._defaults\u001B[39m\u001B[34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001B[39m\n\u001B[32m   2183\u001B[39m     checkpointer = \u001B[38;5;28mself\u001B[39m.checkpointer\n\u001B[32m   2184\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m checkpointer \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config.get(CONF):\n\u001B[32m-> \u001B[39m\u001B[32m2185\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2186\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCheckpointer requires one or more of the following \u001B[39m\u001B[33m'\u001B[39m\u001B[33mconfigurable\u001B[39m\u001B[33m'\u001B[39m\u001B[33m keys: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[s.id\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39ms\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mcheckpointer.config_specs]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   2187\u001B[39m     )\n\u001B[32m   2188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m CONFIG_KEY_STORE \u001B[38;5;129;01min\u001B[39;00m config.get(CONF, {}):\n\u001B[32m   2189\u001B[39m     store: BaseStore | \u001B[38;5;28;01mNone\u001B[39;00m = config[CONF][CONFIG_KEY_STORE]\n",
      "\u001B[31mValueError\u001B[39m: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "# display(Image(math_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(websearch_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(framenet_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "6fb01b822c99559e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 times 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "e54ed6f87aad0a36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is the value of 2 + 10\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "fc9e1a5c75b55215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is apple company founder\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "b9980ce4b212f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f631ea35b1ae8d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T11:31:59.477932Z",
     "start_time": "2025-05-13T11:31:59.476069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google and what is the framenet representation of apple\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7eb90ed0041629cc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T11:32:02.295127Z",
     "start_time": "2025-05-13T11:32:02.293584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google, what is the framenet representation of apple and how much is 2 times 10\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7274ab3752af7aaf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3481b4af5579e10f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
