{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Agents are connected but have their own states. Only the final responses are appended to global state\n",
    "\n",
    "<img src=\"../../resources/images/multi_agent_supervisor.png\" alt=\"Multi Agent Supervisor\" height=\"300\" width=\"300\">\n",
    "\n",
    "Agents are independent LangChain agents. This means they have their own individual prompt, LLM, and tools."
   ],
   "id": "bd92306529b510c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:50:24.909722Z",
     "start_time": "2025-05-13T14:50:24.346578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "from src.langchain.lg_workflow import *\n",
    "from src.langchain.agents.framenet_agent import *"
   ],
   "id": "3442cb04371686b8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:54:42.767303Z",
     "start_time": "2025-05-13T13:54:40.629382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fnr = framenet_tool.invoke({'instruction':'pick up the cup'})\n",
    "fnr"
   ],
   "id": "3bd3077ecf3cf38a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE FRAMENET TOOL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"cup\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"surface\",\\n    \"goal\": \"cup\",\\n    \"result\": \"robot has the cup\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during operation\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:54:57.378844Z",
     "start_time": "2025-05-13T13:54:44.508542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"framenet representation of the action pick up the mug from the sink\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "d1d826be26eb7678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE FRAMENET TOOL\n",
      "(('framenet:4e82edc6-c0e3-8b96-d4f6-309e197939d9',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2025-05-13T13:54:50.06727488Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4926080106, 'load_duration': 8142009, 'prompt_eval_count': 294, 'prompt_eval_duration': 40061265, 'eval_count': 352, 'eval_duration': 4871349509, 'model_name': 'qwen3:8b'}, id='run--238ded2f-a2bf-4642-9fbe-46f9b271adec-0', tool_calls=[{'name': 'framenet_tool', 'args': {'instruction': 'pick up the mug from the sink'}, 'id': '5f885a89-5ad9-4db2-bf24-9301530a88ee', 'type': 'tool_call'}], usage_metadata={'input_tokens': 294, 'output_tokens': 352, 'total_tokens': 646})]}})\n",
      "----\n",
      "(('framenet:4e82edc6-c0e3-8b96-d4f6-309e197939d9',), {'tools': {'messages': [ToolMessage(content='{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"sink\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen workspace\",\\n    \"manner\": \"gently\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during cleanup phase\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}', name='framenet_tool', id='2a77565f-b535-4c61-bbe1-1a30adbdec18', tool_call_id='5f885a89-5ad9-4db2-bf24-9301530a88ee')]}})\n",
      "----\n",
      "(('framenet:4e82edc6-c0e3-8b96-d4f6-309e197939d9',), {'agent': {'messages': [AIMessage(content='<think>\\nOkay, let me break this down. The user asked for a FrameNet representation of the action \"pick up the mug from the sink.\" I called the framenet_tool with that instruction. The response came back with a structured output.\\n\\nFirst, I need to present the FrameNet representation as specified. The main elements are the frame \"Getting\" with the lexical unit \"pick up.v\". The core elements include agent (robot), theme_patient (mug), instrument (robot gripper), source (sink), and the result. Peripheral details like location, manner, etc., are also there.\\n\\nI should format this in a clear, organized way. Maybe start with the frame and lexical unit, then list the core elements, followed by peripheral. Use bullet points or sections for readability. Make sure to mention each part as per the tool\\'s output without adding extra info. Keep it straightforward since the user probably wants a direct answer without explanations.\\n</think>\\n\\nHere is the FrameNet representation for the action \"pick up the mug from the sink\":\\n\\n```\\nFrame: Getting\\nLexical Unit: pick up.v\\nCore Elements:\\n  - agent: robot\\n  - theme_patient: mug\\n  - instrument: robot gripper\\n  - source: sink\\n  - result: robot has the mug\\n\\nPeripheral Elements:\\n  - location: kitchen workspace\\n  - manner: gently\\n  - direction: upward\\n  - time: during cleanup phase\\n  - quantity: one item\\n```', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2025-05-13T13:54:56.604460047Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4305321361, 'load_duration': 8747143, 'prompt_eval_count': 473, 'prompt_eval_duration': 54552714, 'eval_count': 303, 'eval_duration': 4230663600, 'model_name': 'qwen3:8b'}, id='run--f357d78e-7899-4dcb-84c0-b01475084fa5-0', usage_metadata={'input_tokens': 473, 'output_tokens': 303, 'total_tokens': 776})]}})\n",
      "----\n",
      "((), {'framenet': {'messages': [HumanMessage(content='<think>\\nOkay, let me break this down. The user asked for a FrameNet representation of the action \"pick up the mug from the sink.\" I called the framenet_tool with that instruction. The response came back with a structured output.\\n\\nFirst, I need to present the FrameNet representation as specified. The main elements are the frame \"Getting\" with the lexical unit \"pick up.v\". The core elements include agent (robot), theme_patient (mug), instrument (robot gripper), source (sink), and the result. Peripheral details like location, manner, etc., are also there.\\n\\nI should format this in a clear, organized way. Maybe start with the frame and lexical unit, then list the core elements, followed by peripheral. Use bullet points or sections for readability. Make sure to mention each part as per the tool\\'s output without adding extra info. Keep it straightforward since the user probably wants a direct answer without explanations.\\n</think>\\n\\nHere is the FrameNet representation for the action \"pick up the mug from the sink\":\\n\\n```\\nFrame: Getting\\nLexical Unit: pick up.v\\nCore Elements:\\n  - agent: robot\\n  - theme_patient: mug\\n  - instrument: robot gripper\\n  - source: sink\\n  - result: robot has the mug\\n\\nPeripheral Elements:\\n  - location: kitchen workspace\\n  - manner: gently\\n  - direction: upward\\n  - time: during cleanup phase\\n  - quantity: one item\\n```', additional_kwargs={}, response_metadata={}, name='framenet')]}})\n",
      "----\n",
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:06:41.682174Z",
     "start_time": "2025-05-13T14:06:28.326607Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the mug from the fridge')]})['messages'][0].content",
   "id": "b827a45b1d8ad47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "INSIDE FRAMENET TOOL\n",
      "Next Worker: FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'framenet representation of the action pick up the mug from the fridge'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:07:01.087586Z",
     "start_time": "2025-05-13T14:06:44.972079Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the mug from the fridge')]})['messages'][1].content",
   "id": "5547cddfa73627e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "INSIDE FRAMENET TOOL\n",
      "Next Worker: FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user asked for the FrameNet representation of \"pick up the mug from the fridge.\" I called the framenet_tool with that instruction. The response came back with the frame \"Getting\" and the lexical unit \"pick up.v\". The core elements have agent as robot, theme_patient as mug, instrument as robot gripper, source as fridge, and the result is the robot having the mug. Peripheral details include location, manner, direction, etc.\\n\\nNow, I need to present this information as the final answer. The user probably wants a clear, structured output without extra explanations. Let me format the response using the FrameNet elements provided. Make sure to include all the core and peripheral elements as listed. Use the exact terms from the tool\\'s response. Avoid any markdown and just present the data in a readable way. Check if all the keys and values are correctly transcribed. Alright, that should do it.\\n</think>\\n\\n{\\n  \"framenet\": \"picking_up\",\\n  \"frame\": \"Getting\",\\n  \"lexical-unit\": \"pick up.v\",\\n  \"core\": {\\n    \"agent\": \"robot\",\\n    \"theme_patient\": \"mug\",\\n    \"instrument\": \"robot gripper\",\\n    \"source\": \"fridge\",\\n    \"goal\": \"\",\\n    \"result\": \"robot has the mug\"\\n  },\\n  \"peripheral\": {\\n    \"location\": \"kitchen\",\\n    \"manner\": \"carefully\",\\n    \"direction\": \"upward\",\\n    \"time\": \"during retrieval\",\\n    \"quantity\": \"one item\",\\n    \"portion\": \"\"\\n  }\\n}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:50:49.084864Z",
     "start_time": "2025-05-13T14:50:28.364509Z"
    }
   },
   "cell_type": "code",
   "source": "framenet_agent.invoke({'messages': [HumanMessage(content='pick up the mug from the sink')]})",
   "id": "1b4fdcbaed17b4e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE FRAMENET TOOL\n",
      "INSIDE FRAMENET TOOL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='pick up the mug from the sink', additional_kwargs={}, response_metadata={}, id='0c900108-fb9d-49c0-ad45-a73345423c53'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2025-05-13T14:50:39.709835015Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11338841794, 'load_duration': 1242114656, 'prompt_eval_count': 282, 'prompt_eval_duration': 146014174, 'eval_count': 739, 'eval_duration': 9942925922, 'model_name': 'qwen3:8b'}, id='run--9ff62ee9-c613-4f62-8343-f5da287fd2bd-0', tool_calls=[{'name': 'framenet_tool', 'args': {'instruction': 'pick up the mug from the sink'}, 'id': '91594288-2c08-4c94-80a7-911b4866e791', 'type': 'tool_call'}, {'name': 'framenet_tool', 'args': {'instruction': 'pick up the mug from the sink'}, 'id': '9924449d-9bb5-4fac-8d38-1eebe6c7a96b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 739, 'total_tokens': 1021}),\n",
       "  ToolMessage(content='\"{\\\\n  \\\\\"framenet\\\\\": \\\\\"picking_up\\\\\",\\\\n  \\\\\"frame\\\\\": \\\\\"Getting\\\\\",\\\\n  \\\\\"lexical-unit\\\\\": \\\\\"pick up.v\\\\\",\\\\n  \\\\\"core\\\\\": {\\\\n    \\\\\"agent\\\\\": \\\\\"robot\\\\\",\\\\n    \\\\\"theme_patient\\\\\": \\\\\"mug\\\\\",\\\\n    \\\\\"instrument\\\\\": \\\\\"robot gripper\\\\\",\\\\n    \\\\\"source\\\\\": \\\\\"sink\\\\\",\\\\n    \\\\\"goal\\\\\": \\\\\"\\\\\",\\\\n    \\\\\"result\\\\\": \\\\\"robot has the mug\\\\\"\\\\n  },\\\\n  \\\\\"peripheral\\\\\": {\\\\n    \\\\\"location\\\\\": \\\\\"kitchen workspace\\\\\",\\\\n    \\\\\"manner\\\\\": \\\\\"gently\\\\\",\\\\n    \\\\\"direction\\\\\": \\\\\"upward\\\\\",\\\\n    \\\\\"time\\\\\": \\\\\"during cleanup phase\\\\\",\\\\n    \\\\\"quantity\\\\\": \\\\\"one item\\\\\",\\\\n    \\\\\"portion\\\\\": \\\\\"\\\\\"\\\\n  }\\\\n}\"', name='framenet_tool', id='817eac5d-8aa0-4e5e-ae03-5adaf0efca40', tool_call_id='91594288-2c08-4c94-80a7-911b4866e791'),\n",
       "  ToolMessage(content='\"{\\\\n  \\\\\"framenet\\\\\": \\\\\"picking_up\\\\\",\\\\n  \\\\\"frame\\\\\": \\\\\"Getting\\\\\",\\\\n  \\\\\"lexical-unit\\\\\": \\\\\"pick up.v\\\\\",\\\\n  \\\\\"core\\\\\": {\\\\n    \\\\\"agent\\\\\": \\\\\"robot\\\\\",\\\\n    \\\\\"theme_patient\\\\\": \\\\\"mug\\\\\",\\\\n    \\\\\"instrument\\\\\": \\\\\"robot gripper\\\\\",\\\\n    \\\\\"source\\\\\": \\\\\"sink\\\\\",\\\\n    \\\\\"goal\\\\\": \\\\\"\\\\\",\\\\n    \\\\\"result\\\\\": \\\\\"robot has the mug\\\\\"\\\\n  },\\\\n  \\\\\"peripheral\\\\\": {\\\\n    \\\\\"location\\\\\": \\\\\"kitchen workspace\\\\\",\\\\n    \\\\\"manner\\\\\": \\\\\"gently\\\\\",\\\\n    \\\\\"direction\\\\\": \\\\\"upward\\\\\",\\\\n    \\\\\"time\\\\\": \\\\\"during cleanup phase\\\\\",\\\\n    \\\\\"quantity\\\\\": \\\\\"one item\\\\\",\\\\n    \\\\\"portion\\\\\": \\\\\"\\\\\"\\\\n  }\\\\n}\"', name='framenet_tool', id='d22fe1f4-d50d-4e9f-b15d-d99ed58a82b0', tool_call_id='9924449d-9bb5-4fac-8d38-1eebe6c7a96b'),\n",
       "  AIMessage(content='<think>\\nOkay, the user asked the robot to \"pick up the mug from the sink\". I used the FrameNet tool to analyze this instruction. The tool returned a detailed semantic representation. Let me break down the key elements.\\n\\nFirst, the frame identified is \"Getting\" with the lexical unit \"pick up.v\". The core elements include the agent as the robot, the patient (theme_patient) as the mug, the instrument being the robot gripper, and the source (location) as the sink. The result is that the robot now has the mug. Peripheral details mention the location as the kitchen workspace, manner gently, direction upward, time during cleanup, quantity one item, and no portion specified.\\n\\nI need to present this in a clear, user-friendly way. The user probably wants to know the action\\'s components without technical jargon. So, I\\'ll summarize the main parts: who did what, with what, from where, and the outcome. Also, mention any additional context like the location and how it was done. Make sure to highlight the key roles like agent, patient, and source since those are crucial for understanding the task.\\n</think>\\n\\nThe FrameNet analysis for \"pick up the mug from the sink\" reveals the following semantic structure:\\n\\n**Frame**: Getting  \\n**Lexical Unit**: pick up.v  \\n**Core Roles**:  \\n- **Agent**: robot (performer of the action)  \\n- **Patient**: mug (object being picked up)  \\n- **Instrument**: robot gripper (tool used)  \\n- **Source**: sink (location of the object)  \\n- **Result**: robot has the mug  \\n\\n**Peripheral Context**:  \\n- **Location**: kitchen workspace  \\n- **Manner**: gently  \\n- **Direction**: upward  \\n- **Time**: during cleanup phase  \\n- **Quantity**: one item  \\n\\nThis breakdown captures the key actors, objects, and contextual details of the instruction.', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2025-05-13T14:50:49.081019351Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5363646350, 'load_duration': 8232562, 'prompt_eval_count': 672, 'prompt_eval_duration': 160156387, 'eval_count': 387, 'eval_duration': 5179019768, 'model_name': 'qwen3:8b'}, id='run--0fd19a5b-de77-44a4-a033-eb252165f8f5-0', usage_metadata={'input_tokens': 672, 'output_tokens': 387, 'total_tokens': 1059})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "# display(Image(math_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(websearch_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(framenet_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "6fb01b822c99559e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 times 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "e54ed6f87aad0a36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is the value of 2 + 10\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "fc9e1a5c75b55215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is apple company founder\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "b9980ce4b212f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f631ea35b1ae8d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T11:31:59.477932Z",
     "start_time": "2025-05-13T11:31:59.476069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google and what is the framenet representation of apple\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7eb90ed0041629cc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T11:32:02.295127Z",
     "start_time": "2025-05-13T11:32:02.293584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google, what is the framenet representation of apple and how much is 2 times 10\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7274ab3752af7aaf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3481b4af5579e10f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
