{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Agents are connected but have their own states. Only the final responses are appended to global state\n",
    "\n",
    "<img src=\"../../resources/images/multi_agent_supervisor.png\" alt=\"Multi Agent Supervisor\" height=\"300\" width=\"300\">\n",
    "\n",
    "Agents are independent LangChain agents. This means they have their own individual prompt, LLM, and tools."
   ],
   "id": "bd92306529b510c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:31:15.380337Z",
     "start_time": "2025-05-16T09:31:14.546346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "from src.langchain.lg_workflow import *\n",
    "from src.langchain.agents.framenet_agent import *\n",
    "from src.langchain.agents.flanagan_agent import *\n",
    "config = {\"configurable\" : {\"thread_id\" : 1}}"
   ],
   "id": "3442cb04371686b8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fnr = framenet_tool.invoke({'instruction':'pick up the cup'})\n",
    "fnr"
   ],
   "id": "3bd3077ecf3cf38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T12:41:31.402384Z",
     "start_time": "2025-05-15T12:41:28.093174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 plus 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "d1d826be26eb7678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: mather\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE ADD TOOL\n",
      "(('mather:602afda2-fe2b-f36a-9631-e4cbd6d7ea1e',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WO6e3rVPumWplTjFxlA1PeFL', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 94, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6fc597af-f7c2-449c-82ad-30953974d890-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'call_WO6e3rVPumWplTjFxlA1PeFL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 94, 'output_tokens': 18, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "(('mather:602afda2-fe2b-f36a-9631-e4cbd6d7ea1e',), {'tools': {'messages': [ToolMessage(content='4.0', name='add', id='7ae616a5-ba6e-43d3-943b-f834aea94501', tool_call_id='call_WO6e3rVPumWplTjFxlA1PeFL')]}})\n",
      "----\n",
      "(('mather:602afda2-fe2b-f36a-9631-e4cbd6d7ea1e',), {'agent': {'messages': [AIMessage(content='4.0', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 121, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run--b6ae032e-ed21-43a8-a27e-2b6da699f768-0', usage_metadata={'input_tokens': 121, 'output_tokens': 4, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "----\n",
      "((), {'mather': {'messages': [HumanMessage(content='4.0', additional_kwargs={}, response_metadata={}, name='mather')]}})\n",
      "----\n",
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(graph.get_state(config))",
   "id": "5fe2bd5f0a565fd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:25:52.457841Z",
     "start_time": "2025-05-16T09:25:44.341103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"framenet representation of the action instruction pour water from the bottle into the container.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "5c21296a78044bb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: framenet\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE FRAMENET TOOL\n",
      "(('framenet:1e22cc7b-4ea7-fec2-fcfa-9818bb786999',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:25:46.759065362Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1387892955, 'load_duration': 8210143, 'prompt_eval_count': 189, 'prompt_eval_duration': 28310992, 'eval_count': 145, 'eval_duration': 1347833299, 'model_name': 'qwen3:4b'}, id='run--cbddf267-f2eb-434a-9d8d-cc0093fba1df-0', tool_calls=[{'name': 'framenet_tool', 'args': {'__arg1': 'pour water from the bottle into the container.'}, 'id': '6cb3e308-c9f9-4d8c-89e3-d1e984f8ba8d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 189, 'output_tokens': 145, 'total_tokens': 334})]}})\n",
      "----\n",
      "(('framenet:1e22cc7b-4ea7-fec2-fcfa-9818bb786999',), {'tools': {'messages': [ToolMessage(content='\"{\\\\n  \\\\\"framenet\\\\\": \\\\\"pouring\\\\\",\\\\n  \\\\\"frame\\\\\": \\\\\"Pouring\\\\\",\\\\n  \\\\\"lexical-unit\\\\\": \\\\\"pour.v\\\\\",\\\\n  \\\\\"core\\\\\": {\\\\n    \\\\\"agent\\\\\": \\\\\"robot\\\\\",\\\\n    \\\\\"theme_patient\\\\\": \\\\\"water\\\\\",\\\\n    \\\\\"instrument\\\\\": \\\\\"bottle\\\\\",\\\\n    \\\\\"source\\\\\": \\\\\"bottle\\\\\",\\\\n    \\\\\"goal\\\\\": \\\\\"container\\\\\",\\\\n    \\\\\"result\\\\\": \\\\\"container has water\\\\\"\\\\n  },\\\\n  \\\\\"peripheral\\\\\": {\\\\n    \\\\\"location\\\\\": \\\\\"kitchen workspace\\\\\",\\\\n    \\\\\"manner\\\\\": \\\\\"steadily\\\\\",\\\\n    \\\\\"direction\\\\\": \\\\\"downward\\\\\",\\\\n    \\\\\"time\\\\\": \\\\\"during preparation\\\\\",\\\\n    \\\\\"quantity\\\\\": \\\\\"one container\\\\\",\\\\n    \\\\\"portion\\\\\": \\\\\"full\\\\\"\\\\n  }\\\\n}\"', name='framenet_tool', id='7c9d88ae-f092-4ce6-b9d1-b9755f931b40', tool_call_id='6cb3e308-c9f9-4d8c-89e3-d1e984f8ba8d')]}})\n",
      "----\n",
      "(('framenet:1e22cc7b-4ea7-fec2-fcfa-9818bb786999',), {'agent': {'messages': [AIMessage(content='<think>\\nOkay, let\\'s see. The user asked for the FrameNet representation of the action instruction \"pour water from the bottle into the container.\" I called the framenet_tool with that sentence, and the response came back with a structured JSON.\\n\\nFirst, I need to parse the tool\\'s response. The main frame is \"Pouring\" with the lexical unit \"pour.v\". The core elements include the agent as \"robot\", theme_patient as \"water\", instrument as \"bottle\", source as \"bottle\", goal as \"container\", and result as \"container has water\". Then there\\'s the peripheral information with location, manner, direction, time, quantity, and portion.\\n\\nNow, I need to present this information in a clear and concise way. The user probably wants to understand the components of the action as per FrameNet. I should list the frame, lexical unit, and then break down the core and peripheral elements. Make sure to mention each part like agent, theme, instrument, etc., and the peripheral aspects. Avoid any technical jargon but stay accurate. Also, check if the user needs further explanation on any part, but since they just asked for the representation, maybe just present the structured info clearly.\\n</think>\\n\\nThe FrameNet representation of the action instruction \"pour water from the bottle into the container\" is as follows:\\n\\n**Frame**: Pouring  \\n**Lexical Unit**: pour.v  \\n\\n**Core**:  \\n- **Agent**: robot  \\n- **Theme/Patient**: water  \\n- **Instrument**: bottle  \\n- **Source**: bottle  \\n- **Goal**: container  \\n- **Result**: container has water  \\n\\n**Peripheral**:  \\n- **Location**: kitchen workspace  \\n- **Manner**: steadily  \\n- **Direction**: downward  \\n- **Time**: during preparation  \\n- **Quantity**: one container  \\n- **Portion**: full', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:25:51.479115606Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3320647060, 'load_duration': 8237643, 'prompt_eval_count': 394, 'prompt_eval_duration': 30927460, 'eval_count': 375, 'eval_duration': 3270365474, 'model_name': 'qwen3:4b'}, id='run--ce52381b-be7e-429c-87db-a683a280bf53-0', usage_metadata={'input_tokens': 394, 'output_tokens': 375, 'total_tokens': 769})]}})\n",
      "----\n",
      "((), {'framenet': {'messages': [HumanMessage(content='<think>\\nOkay, let\\'s see. The user asked for the FrameNet representation of the action instruction \"pour water from the bottle into the container.\" I called the framenet_tool with that sentence, and the response came back with a structured JSON.\\n\\nFirst, I need to parse the tool\\'s response. The main frame is \"Pouring\" with the lexical unit \"pour.v\". The core elements include the agent as \"robot\", theme_patient as \"water\", instrument as \"bottle\", source as \"bottle\", goal as \"container\", and result as \"container has water\". Then there\\'s the peripheral information with location, manner, direction, time, quantity, and portion.\\n\\nNow, I need to present this information in a clear and concise way. The user probably wants to understand the components of the action as per FrameNet. I should list the frame, lexical unit, and then break down the core and peripheral elements. Make sure to mention each part like agent, theme, instrument, etc., and the peripheral aspects. Avoid any technical jargon but stay accurate. Also, check if the user needs further explanation on any part, but since they just asked for the representation, maybe just present the structured info clearly.\\n</think>\\n\\nThe FrameNet representation of the action instruction \"pour water from the bottle into the container\" is as follows:\\n\\n**Frame**: Pouring  \\n**Lexical Unit**: pour.v  \\n\\n**Core**:  \\n- **Agent**: robot  \\n- **Theme/Patient**: water  \\n- **Instrument**: bottle  \\n- **Source**: bottle  \\n- **Goal**: container  \\n- **Result**: container has water  \\n\\n**Peripheral**:  \\n- **Location**: kitchen workspace  \\n- **Manner**: steadily  \\n- **Direction**: downward  \\n- **Time**: during preparation  \\n- **Quantity**: one container  \\n- **Portion**: full', additional_kwargs={}, response_metadata={}, name='framenet')]}})\n",
      "----\n",
      "Next Worker: FINISH\n",
      "((), {'supervisor': None})\n",
      "----\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:25:56.272016Z",
     "start_time": "2025-05-16T09:25:56.268951Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config)",
   "id": "bd7982a94a5903db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='framenet representation of the action instruction pour water from the bottle into the container.', additional_kwargs={}, response_metadata={}, id='49ecf4fa-5ce7-4ced-81a4-319b1b1fbcfe'), HumanMessage(content='<think>\\nOkay, let\\'s see. The user asked for the FrameNet representation of the action instruction \"pour water from the bottle into the container.\" I called the framenet_tool with that sentence, and the response came back with a structured JSON.\\n\\nFirst, I need to parse the tool\\'s response. The main frame is \"Pouring\" with the lexical unit \"pour.v\". The core elements include the agent as \"robot\", theme_patient as \"water\", instrument as \"bottle\", source as \"bottle\", goal as \"container\", and result as \"container has water\". Then there\\'s the peripheral information with location, manner, direction, time, quantity, and portion.\\n\\nNow, I need to present this information in a clear and concise way. The user probably wants to understand the components of the action as per FrameNet. I should list the frame, lexical unit, and then break down the core and peripheral elements. Make sure to mention each part like agent, theme, instrument, etc., and the peripheral aspects. Avoid any technical jargon but stay accurate. Also, check if the user needs further explanation on any part, but since they just asked for the representation, maybe just present the structured info clearly.\\n</think>\\n\\nThe FrameNet representation of the action instruction \"pour water from the bottle into the container\" is as follows:\\n\\n**Frame**: Pouring  \\n**Lexical Unit**: pour.v  \\n\\n**Core**:  \\n- **Agent**: robot  \\n- **Theme/Patient**: water  \\n- **Instrument**: bottle  \\n- **Source**: bottle  \\n- **Goal**: container  \\n- **Result**: container has water  \\n\\n**Peripheral**:  \\n- **Location**: kitchen workspace  \\n- **Manner**: steadily  \\n- **Direction**: downward  \\n- **Time**: during preparation  \\n- **Quantity**: one container  \\n- **Portion**: full', additional_kwargs={}, response_metadata={}, name='framenet', id='335d4a49-0ab6-4ec6-9f31-0bddad828862')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03237c-2fe5-63e5-8003-ebff6637161c'}}, metadata={'source': 'loop', 'writes': {'supervisor': None}, 'step': 3, 'parents': {}, 'thread_id': 1}, created_at='2025-05-16T09:25:52.452238+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03237c-26a3-63d2-8002-a142d1a2b1a8'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the cup from the fridge')]}, config=config)['messages'][0].content",
   "id": "9dffdd1545ffc558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.get_state(config=config)",
   "id": "b827a45b1d8ad47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# graph.get_state(config=config).values['messages'][-1].content\n",
    "framenet_answers"
   ],
   "id": "accb1841acaf3fa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the mug from the fridge')]})['messages'][1].content",
   "id": "5547cddfa73627e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T09:32:59.428084Z",
     "start_time": "2025-05-16T09:31:24.897075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"flanagan representation of the action instruction pour water from the bottle into the container.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "1b4fdcbaed17b4e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Worker: flanagan\n",
      "((), {'supervisor': None})\n",
      "----\n",
      "INSIDE flanagan TOOL\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:31:33.464844328Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6640294565, 'load_duration': 8372327, 'prompt_eval_count': 186, 'prompt_eval_duration': 22334224, 'eval_count': 762, 'eval_duration': 6605886177, 'model_name': 'qwen3:4b'}, id='run--63584edf-9e8b-4591-984f-8ed1447b0ed4-0', tool_calls=[{'name': 'flanagan_tool', 'args': {'__arg1': 'pour water from the bottle into the container'}, 'id': 'e676eaa1-7dee-45e5-9e2d-7de3a2257d0f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 186, 'output_tokens': 762, 'total_tokens': 948})]}})\n",
      "----\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'tools': {'messages': [ToolMessage(content='{\"llm_flanagan\": \"task=\\'pour water from the bottle into the container\\' pre_motion_phase=FullPhase(goal_definition=GoalDefinition(task=\\'pour water from the bottle into the container\\', semantic_annotation=\\'FrameNet: Pouring\\', object=ObjectModel(id=\\'bottle\\', type=\\'container\\', properties=ObjectProperties(size=None, texture=None, material=None, fill_level=\\'full\\', contents=\\'water\\', hardness=None, friction_coefficient=None, elasticity=None, strain_limit=None), expected_end_state=None), target=ObjectModel(id=\\'container\\', type=\\'container\\', properties=ObjectProperties(size=None, texture=None, material=None, fill_level=\\'empty\\', contents=\\'empty\\', hardness=None, friction_coefficient=None, elasticity=None, strain_limit=None), expected_end_state=None), tool=ToolModel(id=\\'bottle\\', type=\\'container\\', properties={\\'fill_level\\': \\'full\\', \\'content\\': \\'water\\'})), predictive_model=PredictiveModel(expected_trajectory=\\'pour\\', expected_force={\\'grip\\': 4.5, \\'tilt\\': 1.3}, confidence_level=0.98, affordance_model={\\'affordances\\': False}), motion_planning=MotionPlanning(planned_trajectory=\\'pour\\', obstacle_avoidance=\\'no_obstacles\\', energy_efficiency=\\'high\\')) initiation_phase=InitialPhase(initial_state=InitialState(robot_pose={\\'position\\': [0.3, 0.0, 0.3], \\'orientation\\': [0.0, 0.0, 0.0, 1.0]}, tool_position=[0.3, 0.0, 0.3], target_object_position=[0.5, 0.5, 0.2]), motion_initialization=MotionInitialization(joint_activation={\\'gripper\\': 0.5, \\'arm\\': 0.8}, velocity_profile=\\'linear\\', motion_priming={\\'gripper\\': True, \\'arm\\': True}), SubPhases=[SubPhase(name=\\'Orientation\\', description=\\'Position the bottle to pour\\', goalState=GoalState(conditions={\\'bottle_oriented\\': {\\'true\\': True}})), SubPhase(name=\\'Grasp\\', description=\\'Grasp the bottle\\', goalState=GoalState(conditions={\\'bottle_grasped\\': {\\'true\\': True}})), SubPhase(name=\\'Approach\\', description=\\'Approach the container\\', goalState=GoalState(conditions={\\'container_approached\\': {\\'true\\': True}}))], SymbolicGoals=GoalState(conditions={\\'bottle_oriented\\': {\\'true\\': True}, \\'bottle_grasped\\': {\\'true\\': True}, \\'container_approached\\': {\\'true\\': True}}), SemanticAnnotation=\\'FrameNet: Pouring\\') execution_phase=Phase(SubPhases=[SubPhase(name=\\'Pour\\', description=\\'Pour water from the bottle into the container\\', goalState=GoalState(conditions={\\'pouring\\': {\\'true\\': True}})), SubPhase(name=\\'MonitorFlow\\', description=\\'Monitor the flow of water\\', goalState=GoalState(conditions={\\'flow_monitored\\': {\\'true\\': True}})), SubPhase(name=\\'AdjustTilt\\', description=\\\\\"Adjust the bottle\\'s tilt to control the flow\\\\\", goalState=GoalState(conditions={\\'tilt_adjusted\\': {\\'true\\': True}}))], SymbolicGoals=GoalState(conditions={\\'pouring\\': {\\'true\\': True}, \\'flow_monitored\\': {\\'true\\': True}, \\'tilt_adjusted\\': {\\'true\\': True}}), SemanticAnnotation=\\'FrameNet: Pouring\\') interaction_phase=Phase(SubPhases=[SubPhase(name=\\'TiltBottle\\', description=\\'Tilt the bottle to initiate the pour\\', goalState=GoalState(conditions={\\'bottle_tilted\\': {\\'true\\': True}})), SubPhase(name=\\'ControlFlow\\', description=\\'Control the flow of water\\', goalState=GoalState(conditions={\\'flow_controlled\\': {\\'true\\': True}})), SubPhase(name=\\'StopPouring\\', description=\\'Stop the pouring when the container is full\\', goalState=GoalState(conditions={\\'pouring_stopped\\': {\\'true\\': True}}))], SymbolicGoals=GoalState(conditions={\\'bottle_tilted\\': {\\'true\\': True}, \\'flow_controlled\\': {\\'true\\': True}, \\'pouring_stopped\\': {\\'true\\': True}}), SemanticAnnotation=\\'FrameNet: Pouring\\') termination_phase=Phase(SubPhases=[SubPhase(name=\\'ReleaseBottle\\', description=\\'Release the bottle after pouring\\', goalState=GoalState(conditions={\\'bottle_released\\': {\\'true\\': True}})), SubPhase(name=\\'ReturnToHome\\', description=\\'Return the robot to its home position\\', goalState=GoalState(conditions={\\'robot_home\\': {\\'true\\': True}}))], SymbolicGoals=GoalState(conditions={\\'bottle_released\\': {\\'true\\': True}, \\'robot_home\\': {\\'true\\': True}}), SemanticAnnotation=\\'FrameNet: Pouring\\') post_motion_phase=Phase(SubPhases=[SubPhase(name=\\'CheckFillLevel\\', description=\\'Check the fill level of the container\\', goalState=GoalState(conditions={\\'container_filled\\': {\\'true\\': True}})), SubPhase(name=\\'RecordPour\\', description=\\'Record the pouring event\\', goalState=GoalState(conditions={\\'pour_recorded\\': {\\'true\\': True}}))], SymbolicGoals=GoalState(conditions={\\'container_filled\\': {\\'true\\': True}, \\'pour_recorded\\': {\\'true\\': True}}), SemanticAnnotation=\\'FrameNet: Pouring\\')\"}', name='flanagan_tool', id='e668960c-0686-4f3a-8b08-bd8184c2b97e', tool_call_id='e676eaa1-7dee-45e5-9e2d-7de3a2257d0f')]}})\n",
      "----\n",
      "INSIDE flanagan TOOL\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:31:53.103363399Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2938998559, 'load_duration': 8337556, 'prompt_eval_count': 1342, 'prompt_eval_duration': 278866004, 'eval_count': 278, 'eval_duration': 2635652334, 'model_name': 'qwen3:4b'}, id='run--93ce9987-7c12-497c-9183-86df6b718e7c-0', tool_calls=[{'name': 'flanagan_tool', 'args': {'__arg1': 'pour water from the bottle into the container'}, 'id': 'd35c3b81-e8f0-4bbd-b132-55ca7749c9fc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1342, 'output_tokens': 278, 'total_tokens': 1620})]}})\n",
      "----\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'tools': {'messages': [ToolMessage(content='{\"llm_flanagan\": \"task=\\'pour water from the bottle into the container\\' pre_motion_phase=FullPhase(goal_definition=GoalDefinition(task=\\'pour water from the bottle into the container\\', semantic_annotation=\\'PhaseClass:PreMotion\\', object=ObjectModel(id=\\'bottle\\', type=\\'object\\', properties=ObjectProperties(size=None, texture=None, material=None, fill_level=None, contents=\\'water\\', hardness=5.0, friction_coefficient=None, elasticity=None, strain_limit=10.0), expected_end_state=GoalState(conditions={\\'container\\': {\\'has\\': True, \\'content\\': True}, \\'bottle\\': {\\'has\\': False, \\'content\\': False}})), target=ObjectModel(id=\\'container\\', type=\\'target\\', properties=ObjectProperties(size=None, texture=None, material=\\'plastic\\', fill_level=None, contents=\\'empty\\', hardness=None, friction_coefficient=None, elasticity=None, strain_limit=20.0), expected_end_state=None), tool=ToolModel(id=\\'robot\\', type=\\'tool\\', properties={\\'efficiency\\': 90.0, \\'precision\\': 95.0})), predictive_model=PredictiveModel(expected_trajectory=\\'Pouring\\', expected_force={\\'initial\\': 4.5, \\'adaptive\\': 4.7}, confidence_level=0.97, affordance_model={\\'affordances\\': True, \\'affordance_id\\': True, \\'affordance_type\\': True}), motion_planning=MotionPlanning(planned_trajectory=\\'Pouring\\', obstacle_avoidance=\\'No obstacles\\', energy_efficiency=\\'value\\')) initiation_phase=InitialPhase(initial_state=InitialState(robot_pose={\\'x\\': [], \\'y\\': [], \\'z\\': []}, tool_position=[], target_object_position=[]), motion_initialization=MotionInitialization(joint_activation={}, velocity_profile=\\'value\\', motion_priming={\\'joint_awareness\\': True, \\'velocity_awareness\\': True}), SubPhases=[SubPhase(name=\\'Approach\\', description=\\'Move robot to position above the container\\', goalState=GoalState(conditions={\\'robot\\': {\\'position\\': True, \\'orientation\\': True}, \\'container\\': {\\'position\\': True, \\'orientation\\': True}})), SubPhase(name=\\'Grasp\\', description=\\'Grasp the bottle\\', goalState=GoalState(conditions={\\'bottle\\': {\\'grasped\\': True}, \\'robot\\': {\\'gripper\\': True}})), SubPhase(name=\\'Align\\', description=\\'Align the bottle with the container\\', goalState=GoalState(conditions={\\'bottle\\': {\\'aligned\\': True}, \\'container\\': {\\'aligned\\': True}}))], SymbolicGoals=GoalState(conditions={\\'robot\\': {\\'position\\': True, \\'orientation\\': True}, \\'container\\': {\\'position\\': True, \\'orientation\\': True}, \\'bottle\\': {\\'grasped\\': True}}), SemanticAnnotation=\\'PhaseClass:Initiation\\') execution_phase=Phase(SubPhases=[SubPhase(name=\\'Pour\\', description=\\'Execute the pour action\\', goalState=GoalState(conditions={\\'flow\\': {\\'initiated\\': True}}))], SymbolicGoals=GoalState(conditions={\\'flow\\': {\\'initiated\\': True}}), SemanticAnnotation=\\'PhaseClass:Execution\\') interaction_phase=Phase(SubPhases=[SubPhase(name=\\'MonitorAndControl\\', description=\\'Monitor the pour process and adjust if necessary\\', goalState=GoalState(conditions={\\'flow\\': {\\'controlled\\': True}}))], SymbolicGoals=GoalState(conditions={\\'flow\\': {\\'controlled\\': True}}), SemanticAnnotation=\\'PhaseClass:Interaction\\') termination_phase=Phase(SubPhases=[SubPhase(name=\\'Release\\', description=\\'Release the bottle after pouring\\', goalState=GoalState(conditions={\\'bottle\\': {\\'released\\': True}}))], SymbolicGoals=GoalState(conditions={\\'bottle\\': {\\'released\\': True}}), SemanticAnnotation=\\'PhaseClass:Termination\\') post_motion_phase=Phase(SubPhases=[SubPhase(name=\\'Verify\\', description=\\'Verify that the container has the water\\', goalState=GoalState(conditions={\\'container\\': {\\'has_water\\': True}}))], SymbolicGoals=GoalState(conditions={\\'container\\': {\\'has_water\\': True}}), SemanticAnnotation=\\'PhaseClass:PostMotion\\')\"}', name='flanagan_tool', id='db5f7081-1940-4086-8f14-499d058c63ec', tool_call_id='d35c3b81-e8f0-4bbd-b132-55ca7749c9fc')]}})\n",
      "----\n",
      "INSIDE flanagan TOOL\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:32:12.84231755Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4363765963, 'load_duration': 8501801, 'prompt_eval_count': 1061, 'prompt_eval_duration': 237570256, 'eval_count': 403, 'eval_duration': 4106676434, 'model_name': 'qwen3:4b'}, id='run--b7757489-cbdb-45e6-acb7-661e2b0ce7f8-0', tool_calls=[{'name': 'flanagan_tool', 'args': {'__arg1': 'pour water from the bottle into the container'}, 'id': '5ba6333f-aa11-43f6-9f68-2bc3ec1cc97a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1061, 'output_tokens': 403, 'total_tokens': 1464})]}})\n",
      "----\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'tools': {'messages': [ToolMessage(content='{\"llm_flanagan\": \"task=\\'pour water from the bottle into the container\\' pre_motion_phase=FullPhase(goal_definition=GoalDefinition(task=\\'pour water from the bottle into the container\\', semantic_annotation=\\'TaskClass:PreMotion\\', object=ObjectModel(id=\\'bottle\\', type=\\'container\\', properties=ObjectProperties(size=None, texture=None, material=None, fill_level=\\'full\\', contents=None, hardness=0.5, friction_coefficient=None, elasticity=None, strain_limit=None), expected_end_state=None), target=ObjectModel(id=\\'container\\', type=\\'container\\', properties=ObjectProperties(size=None, texture=None, material=None, fill_level=\\'empty\\', contents=None, hardness=0.2, friction_coefficient=None, elasticity=None, strain_limit=None), expected_end_state=None), tool=ToolModel(id=\\'bottle\\', type=\\'container\\', properties={\\'fill_level\\': \\'full\\', \\'hardeness\\': 0.5})), predictive_model=PredictiveModel(expected_trajectory=\\'Trajectory:PourFromBottleToContainer\\', expected_force={\\'initial_grip\\': 4.0, \\'tilt_angle\\': 30.0, \\'flow_rate\\': 0.2}, confidence_level=0.92, affordance_model={\\'grip\\': True, \\'tilt\\': True, \\'pour\\': True}), motion_planning=MotionPlanning(planned_trajectory=\\'Trajectory:PourFromBottleToContainer\\', obstacle_avoidance=\\'no obstacles\\', energy_efficiency=\\'value\\')) initiation_phase=InitialPhase(initial_state=InitialState(robot_pose={\\'position\\': [0.5, 0.5, 0.8], \\'orientation\\': [0.0, 0.0, 0.0, 1.0]}, tool_position=[0.5, 0.5, 0.8], target_object_position=[0.6, 0.6, 0.6]), motion_initialization=MotionInitialization(joint_activation={\\'gripper\\': 0.9, \\'arm\\': 0.8}, velocity_profile=\\'slow\\', motion_priming={\\'sensors\\': True, \\'actuators\\': True}), SubPhases=[SubPhase(name=\\'GripAndPosition\\', description=\\'Grip the bottle and position it above the container\\', goalState=GoalState(conditions={\\'bottle_position\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'container_position\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'CheckAndAlign\\', description=\\'Check alignment between bottle and container\\', goalState=GoalState(conditions={\\'alignment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'InitiatePour\\', description=\\'Start the pouring action\\', goalState=GoalState(conditions={\\'pouring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}))], SymbolicGoals=GoalState(conditions={\\'bottle_position\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'container_position\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'alignment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'pouring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}), SemanticAnnotation=\\'TaskClass:Initiation\\') execution_phase=Phase(SubPhases=[SubPhase(name=\\'PouringAction\\', description=\\'Execute the pouring action\\', goalState=GoalState(conditions={\\'pouring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'MonitorFlow\\', description=\\'Monitor the flow of liquid during pouring\\', goalState=GoalState(conditions={\\'flow_monitoring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'AdjustTilt\\', description=\\'Adjust the tilt of the bottle to control the flow rate\\', goalState=GoalState(conditions={\\'tilt_adjustment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}))], SymbolicGoals=GoalState(conditions={\\'pouring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'flow_monitoring\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'tilt_adjustment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}), SemanticAnnotation=\\'TaskClass:Execution\\') interaction_phase=Phase(SubPhases=[SubPhase(name=\\'SensorFeedback\\', description=\\'Receive feedback from sensors during pouring\\', goalState=GoalState(conditions={\\'sensor_feedback\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'AdaptControl\\', description=\\'Adjust control parameters based on sensor feedback\\', goalState=GoalState(conditions={\\'control_adaptation\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'StopPouring\\', description=\\'Stop the pouring action when the container is full\\', goalState=GoalState(conditions={\\'pouring_stopped\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}))], SymbolicGoals=GoalState(conditions={\\'sensor_feedback\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'control_adaptation\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'pouring_stopped\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}), SemanticAnnotation=\\'TaskClass:Interaction\\') termination_phase=Phase(SubPhases=[SubPhase(name=\\'FinalPositioning\\', description=\\'Position the bottle and container after pouring\\', goalState=GoalState(conditions={\\'final_positioning\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'Deactivation\\', description=\\'Deactivate the robot and tools after the task\\', goalState=GoalState(conditions={\\'deactivation\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}))], SymbolicGoals=GoalState(conditions={\\'final_positioning\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'deactivation\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}), SemanticAnnotation=\\'TaskClass:Termination\\') post_motion_phase=Phase(SubPhases=[SubPhase(name=\\'PostureAdjustment\\', description=\\\\\"Adjust the robot\\'s posture after the task\\\\\", goalState=GoalState(conditions={\\'posture_adjustment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}})), SubPhase(name=\\'FinalCheck\\', description=\\'Check the final state of the container and bottle\\', goalState=GoalState(conditions={\\'final_check\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}))], SymbolicGoals=GoalState(conditions={\\'posture_adjustment\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}, \\'final_check\\': {\\'x\\': True, \\'y\\': True, \\'z\\': True}}), SemanticAnnotation=\\'TaskClass:PostMotion\\')\"}', name='flanagan_tool', id='d838da95-10cc-4cfd-b05e-b93d8fc842d5', tool_call_id='5ba6333f-aa11-43f6-9f68-2bc3ec1cc97a')]}})\n",
      "----\n",
      "INSIDE flanagan TOOL\n",
      "(('flanagan:d861f995-50bb-e6cd-8a31-944f3293f18a',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:4b', 'created_at': '2025-05-16T09:32:35.834591448Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3894712520, 'load_duration': 8555226, 'prompt_eval_count': 1672, 'prompt_eval_duration': 405373049, 'eval_count': 326, 'eval_duration': 3468681375, 'model_name': 'qwen3:4b'}, id='run--a11a80a8-1ef5-462e-b634-42d95986a167-0', tool_calls=[{'name': 'flanagan_tool', 'args': {'__arg1': 'pour water from the bottle into the container'}, 'id': 'c734c100-ee9c-47f3-937c-0fede1d88039', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1672, 'output_tokens': 326, 'total_tokens': 1998})]}})\n",
      "----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Example: Complex Query Using Multiple Agents\u001B[39;00m\n\u001B[32m      2\u001B[39m input_question = \u001B[33m\"\u001B[39m\u001B[33mflanagan representation of the action instruction pour water from the bottle into the container.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_question\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubgraphs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m----\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/hometesting/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2461\u001B[39m, in \u001B[36mPregel.stream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2455\u001B[39m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[32m   2456\u001B[39m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[32m   2457\u001B[39m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[32m   2458\u001B[39m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[32m   2459\u001B[39m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[32m   2460\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m loop.tick(input_keys=\u001B[38;5;28mself\u001B[39m.input_channels):\n\u001B[32m-> \u001B[39m\u001B[32m2461\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2462\u001B[39m \u001B[43m            \u001B[49m\u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2463\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2464\u001B[39m \u001B[43m            \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2465\u001B[39m \u001B[43m            \u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2466\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   2467\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# emit output\u001B[39;49;00m\n\u001B[32m   2468\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2469\u001B[39m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/hometesting/lib/python3.11/site-packages/langgraph/pregel/runner.py:218\u001B[39m, in \u001B[36mPregelRunner.tick\u001B[39m\u001B[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[39m\n\u001B[32m    216\u001B[39m end_time = timeout + time.monotonic() \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(futures) > (\u001B[32m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m get_waiter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m0\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m     done, inflight = \u001B[43mconcurrent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    220\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_when\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconcurrent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m.\u001B[49m\u001B[43mFIRST_COMPLETED\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    221\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmonotonic\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    222\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    223\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[32m    224\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# timed out\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.11/concurrent/futures/_base.py:305\u001B[39m, in \u001B[36mwait\u001B[39m\u001B[34m(fs, timeout, return_when)\u001B[39m\n\u001B[32m    301\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001B[32m    303\u001B[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001B[32m--> \u001B[39m\u001B[32m305\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fs:\n\u001B[32m    307\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m f._condition:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.11/threading.py:629\u001B[39m, in \u001B[36mEvent.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    627\u001B[39m signaled = \u001B[38;5;28mself\u001B[39m._flag\n\u001B[32m    628\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[32m--> \u001B[39m\u001B[32m629\u001B[39m     signaled = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cond\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.11/threading.py:327\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[32m    326\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m327\u001B[39m         \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    328\u001B[39m         gotit = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    329\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='flanagan representation of instruction pickup the bottle from the fridge')]}, config=config)['messages'][1].content",
   "id": "de612399a406c7e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flanagan_agent.invoke({'messages': [HumanMessage(content='flanagan representation of instruction pour water from the bottle into the container')]})",
   "id": "589aeddfabda34d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "# display(Image(math_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(websearch_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(framenet_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "6fb01b822c99559e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 times 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "e54ed6f87aad0a36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is the value of 2 + 10\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "fc9e1a5c75b55215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is apple company founder\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "b9980ce4b212f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f631ea35b1ae8d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google and what is the framenet representation of apple\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7eb90ed0041629cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google, what is the framenet representation of apple and how much is 2 times 10\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7274ab3752af7aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3481b4af5579e10f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
