{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Agents are connected but have their own states. Only the final responses are appended to global state\n",
    "\n",
    "<img src=\"../../resources/images/multi_agent_supervisor.png\" alt=\"Multi Agent Supervisor\" height=\"300\" width=\"300\">\n",
    "\n",
    "Agents are independent LangChain agents. This means they have their own individual prompt, LLM, and tools."
   ],
   "id": "bd92306529b510c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "# from src.langchain.lg_workflow import *\n",
    "from src.langchain_flow.agents.framenet_agent import *\n",
    "from src.langchain_flow.agents.pycram_agent import *\n",
    "# from src.langchain.agents.pycram_corrector_agent import *\n",
    "from src.langchain_flow.e2e_workflow import *\n",
    "from src.resources.pycram.pycram_failures import *\n",
    "from src.resources.pycram.pycram_action_designators import *\n",
    "config = {\"configurable\" : {\"thread_id\" : 1}}"
   ],
   "id": "3442cb04371686b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ad Agent",
   "id": "c5d10bdc445a524b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_question = \"the person picks up a brown onion\"\n",
    "for s in ad_agent.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ],
   "id": "e5ecf0a34933bb1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ad_agent.invoke({'messages': [(\"user\", \"pick up the blue cup and go to sink\")]})",
   "id": "d0bb69fc10c27057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Framenet Agent",
   "id": "37d0c51a4f0fbdf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fnr = framenet_tool.invoke({'instruction':'pour water from cup into sink'})\n",
    "fnr"
   ],
   "id": "3bd3077ecf3cf38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(graph.get_state(config))",
   "id": "5fe2bd5f0a565fd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"framenet representation of the action instruction pour water from the bottle into the container.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "5c21296a78044bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.get_state(config)",
   "id": "bd7982a94a5903db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the cup from the fridge')]}, config=config)['messages'][0].content",
   "id": "9dffdd1545ffc558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.get_state(config=config)",
   "id": "b827a45b1d8ad47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# graph.get_state(config=config).values['messages'][-1].content\n",
    "framenet_answers"
   ],
   "id": "accb1841acaf3fa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='framenet representation of the action pick up the mug from the fridge')]})['messages'][1].content",
   "id": "5547cddfa73627e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e34bd9c848e3fc50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Flanagan Agent",
   "id": "5962017aee5d2c96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"flanagan representation of the action instruction pour water from the bottle into the container.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "1b4fdcbaed17b4e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.invoke({'messages': [HumanMessage(content='flanagan representation of instruction pickup the bottle from the fridge')]}, config=config)['messages'][1].content",
   "id": "de612399a406c7e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flanagan_agent.invoke({'messages': [HumanMessage(content='flanagan representation of instruction pour water from the bottle into the container')]})",
   "id": "589aeddfabda34d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# display(Image(math_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(websearch_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(framenet_agent.get_graph().draw_mermaid_png()))\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "6fb01b822c99559e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pycram Agent",
   "id": "f755f645eb04a0bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"pick up the cup and go to sink\"\n",
    "for s in pycram_agent.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True,\n",
    "    config=config,\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "14f94ce6581cbf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pycram_agent.invoke({\"messages\" : [HumanMessage(content=\"pick up the cup from the sink nad place it on the table\")]})\n",
    "# pycram_agent.invoke({\"messages\": \"pick up the cup from the sink\"})"
   ],
   "id": "f82bc2b0adb16954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "instruction_for_populator = {\n",
    "        \"instruction\": \"pick up the cup from the sink\",\n",
    "        \"model_names\": [\"PickUpAction\"]\n",
    "    }"
   ],
   "id": "eaf67983d6da6c5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = model_selector.invoke(\"pick up the cup from the sink\")\n",
    "res"
   ],
   "id": "3262d035f8a0d146",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = model_populator.invoke({\"instruction\":\"pick up the cup from the sink\", \"model_names\": [\"PickUpAction\"]})\n",
    "res"
   ],
   "id": "bd26af86370bfc76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(res['populated_models'])",
   "id": "74cbee8b1420e0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Other Agents",
   "id": "884d46af51343620"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(sole.get_graph().draw_mermaid_png()))"
   ],
   "id": "f7bf7082cb581c31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_obj = ObjectModel(name=\"cup\",concept=\"cup\", color=\"blue\")\n",
    "test_robot = ObjectModel(name=\"robot\", concept=\"robot\")\n",
    "test_links = [Link(name=\"gripper_link\"), Link(name=\"wrist_link\")]\n",
    "test_pose = PoseStamped(pose=Pose(\n",
    "    position=Vector3(x=1.0, y=2.0, z=3.0),\n",
    "    orientation=Quaternion(x=0.0, y=0.0, z=0.0, w=1.0)))\n",
    "\n",
    "action_designator = \"\"\"PickUpAction(object_designator=test_obj, arm=Arms.LEFT,\n",
    "                                 grasp_description=GraspDescription(approach_direction=Grasp.TOP,vertical_alignment=Grasp.TOP, rotate_gripper=True))\"\"\"\n",
    "grasping_error = \"ObjectNotGraspedErrorModel(obj=test_obj, robot=test_robot, arm=Arms.LEFT, grasp=Grasp.TOP)\""
   ],
   "id": "75ef283e8b4fc850",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sole.invoke({\"action_designator\": action_designator, \"reason_for_failure\": grasping_error, \"human_comment\" : \"pick the blue bottle not the cup\"})",
   "id": "45c2d33e6b4a37d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# update_agent.invoke({\"action_designator\": action_designator, \"reason_for_failure\": grasping_error, \"human_comment\" : \"pick the blue bottle not the cup\"})",
   "id": "e769ce4ede76687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for s in designator_updater.stream({\"action_designator\" : action_designator, \"reason_for_failure\" : grasping_error,\n",
    "#                                \"human_comment\" : \"i want to pick up the pink bottle not the blue cup\"}):\n",
    "#     print(s)"
   ],
   "id": "92521de4bf73383b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is 2 times 2\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True, config=config\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "e54ed6f87aad0a36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.get_state(config=config)",
   "id": "1173241696fc4bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example: Complex Query Using Multiple Agents\n",
    "input_question = \"what is the value of 2 + 10\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", input_question)]},\n",
    "    subgraphs=True\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ],
   "id": "fc9e1a5c75b55215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is apple company founder\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "b9980ce4b212f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f631ea35b1ae8d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google and what is the framenet representation of apple\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7eb90ed0041629cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Example: Complex Query Using Multiple Agents\n",
    "# input_question = \"who is the ceo of google, what is the framenet representation of apple and how much is 2 times 10\"\n",
    "# for s in graph.stream(\n",
    "#     {\"messages\": [(\"user\", input_question)]},\n",
    "#     subgraphs=True\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"----\")\n"
   ],
   "id": "7274ab3752af7aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:00:45.520428Z",
     "start_time": "2025-06-24T13:00:45.005644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.resources.flanagan_models.new_flanagan_workflow import *\n",
    "config = {\"configurable\" : {\"thread_id\" : 1}}"
   ],
   "id": "3481b4af5579e10f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying OLLAMA model 14b\n",
      "OLLAMA model found\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:00:45.751065Z",
     "start_time": "2025-06-24T13:00:45.743545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# chain = ChatPromptTemplate.from_template(task_decomposer_prompt_template) | ollama_llm_small.with_structured_output(PhasePlanner, method=\"json_schema\")\n",
    "#\n",
    "# chain_out = chain.invoke({'instruction' : \"pick up the box from the table\"})\n",
    "#\n",
    "# chain2 = ChatPromptTemplate.from_template(phase_normalization_prompt_template) | ollama_llm_small.with_structured_output(NormalizedPhases, method=\"json_schema\")\n",
    "#\n",
    "# chain2_out = chain2.invoke({'action_phases' : chain_out.phases})\n",
    "#\n",
    "# print(\"Normalized phases\",chain2_out.normalized_phases)\n",
    "#\n",
    "# chain3 = ChatPromptTemplate.from_template(precondition_generator_prompt_template) | ollama_llm_small.with_structured_output(PhasePreconditionsMap, method=\"json_schema\")\n",
    "#\n",
    "# chain3_out = chain3.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases})\n",
    "#\n",
    "# print(\"Preconditions\",chain3_out.phase_preconditions)\n",
    "#\n",
    "# chain4 = ChatPromptTemplate.from_template(force_dynamics_prompt_template) | ollama_llm_small.with_structured_output(ForceDynamicsMap, method=\"json_schema\")\n",
    "#\n",
    "# chain4_out = chain4.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases, 'preconditions' : chain3_out.phase_preconditions})\n",
    "#\n",
    "# print(\"Force dynamics\", chain4_out.force_dynamics)\n",
    "#\n",
    "# chain5 = ChatPromptTemplate.from_template(goal_state_generator_prompt_template) | ollama_llm_small.with_structured_output(GoalStateMap, method=\"json_schema\")\n",
    "#\n",
    "# chain5_out = chain5.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases,\n",
    "#                             'preconditions' : chain3_out.phase_preconditions, 'force_dynamics' : chain4_out.force_dynamics})\n",
    "#\n",
    "# print(\"Goal States\", chain5_out.goal_states)\n",
    "#\n",
    "# chain6 = ChatPromptTemplate.from_template(sensory_feedback_predictor_prompt_template) | ollama_llm_small.with_structured_output(SensoryFeedbackMap, method=\"json_schema\")\n",
    "#\n",
    "# chain6_out = chain6.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases,\n",
    "#                             'preconditions' : chain3_out.phase_preconditions, 'force_dynamics' : chain4_out.force_dynamics,\n",
    "#                             'goal_states' : chain5_out.goal_states})\n",
    "#\n",
    "# print(\"Sensory feedbacks\", chain6_out.sensory_feedback)\n",
    "#\n",
    "# chain7 = ChatPromptTemplate.from_template(failure_recovery_prompt_template) | ollama_llm_small.with_structured_output(FailureRecoveryMap, method=\"json_schema\")\n",
    "#\n",
    "# chain7_out = chain7.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases,\n",
    "#                             'preconditions' : chain3_out.phase_preconditions, 'force_dynamics' : chain4_out.force_dynamics,\n",
    "#                             'sensory_feedback' : chain6_out.sensory_feedback, 'goal_states' : chain5_out.goal_states})\n",
    "#\n",
    "# print(\"Failure and recovery\", chain7_out.failure_and_recovery)\n",
    "#\n",
    "# chain8 = ChatPromptTemplate.from_template(temporal_constraints_prompt_template) | ollama_llm_small.with_structured_output(TemporalConstraintsMap, method=\"json_schema\")\n",
    "#\n",
    "# chain8_out = chain8.invoke({'instruction' : \"pick up the box from the table\", 'action_phases' : chain2_out.normalized_phases,\n",
    "#                             'preconditions' : chain3_out.phase_preconditions, 'force_dynamics' : chain4_out.force_dynamics,\n",
    "#                             'sensory_feedback' : chain6_out.sensory_feedback, 'failure_and_recovery' : chain7_out.failure_and_recovery,\n",
    "#                             'goal_states' : chain5_out.goal_states})\n",
    "#\n",
    "# print(\"Temporal constraints\", chain8_out.temporal_constraints)\n",
    "#\n",
    "# flanagan = generate_flanagan_descriptor(\n",
    "#     \"pick up the box from the table\",\n",
    "#     phases= chain2_out.normalized_phases,\n",
    "#     preconditions=chain3_out.phase_preconditions,\n",
    "#     goal_states=chain5_out.goal_states,\n",
    "#     force_dynamics=chain4_out.force_dynamics,\n",
    "#     sensory_feedbacks=chain6_out.sensory_feedback,\n",
    "#     failure_and_recovery=chain7_out.failure_and_recovery,\n",
    "#     temporal_constraints=chain8_out.temporal_constraints\n",
    "# )"
   ],
   "id": "273e73bab266599d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:02.669389Z",
     "start_time": "2025-06-24T13:00:47.255653Z"
    }
   },
   "cell_type": "code",
   "source": "final_flanagan_state = new_flanagan_graph.invoke({'instruction' : \"pick up the blue box from the sink\"}, config=config)",
   "id": "2d6f7f445bd5eeaf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T13:01:10.513436Z",
     "start_time": "2025-06-24T13:01:10.507522Z"
    }
   },
   "cell_type": "code",
   "source": "final_flanagan_state['flanagan']",
   "id": "6d1ab38509e096a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'pick up the blue box from the sink',\n",
       " 'phases': [{'phase': 'Approach',\n",
       "   'symbol': '→[robot performs approach]',\n",
       "   'goal_state': {'object_in_view': True},\n",
       "   'preconditions': {'object_visible': True,\n",
       "    'object_position_known': True,\n",
       "    'gripper_open': True},\n",
       "   'force_dynamics': {'contact': False,\n",
       "    'motion_type': 'linear',\n",
       "    'force_exerted': 'none',\n",
       "    'force_profile': {'type': 'constant',\n",
       "     'expected_range_N': [0.0, 0.0],\n",
       "     'expected_range_Nm': None}},\n",
       "   'sensory_feedback': {'vision_object_in_view': True,\n",
       "    'object_position_verified': True},\n",
       "   'failure_and_recovery': {'possible_failures': ['object_not_in_view',\n",
       "     'object_position_misestimated',\n",
       "     'gripper_not_open'],\n",
       "    'recovery_strategies': ['retry_approach',\n",
       "     'reposition_camera',\n",
       "     'adjust_gripper_state']},\n",
       "   'temporal_constraints': {'max_duration_sec': 2.0, 'urgency': 'medium'}},\n",
       "  {'phase': 'Grasp',\n",
       "   'symbol': '→[robot performs grasp]',\n",
       "   'goal_state': {'object_grasped': True},\n",
       "   'preconditions': {'object_stationary': True,\n",
       "    'gripper_open': True,\n",
       "    'grasp_pose_known': True,\n",
       "    'no_obstacle_above': True},\n",
       "   'force_dynamics': {'contact': True,\n",
       "    'motion_type': 'gripper',\n",
       "    'force_exerted': 'grasp',\n",
       "    'force_profile': {'type': 'step',\n",
       "     'expected_range_N': [5.0, 15.0],\n",
       "     'expected_range_Nm': None}},\n",
       "   'sensory_feedback': {'tactile_contact_detected': True,\n",
       "    'grip_force_within_range': True},\n",
       "   'failure_and_recovery': {'possible_failures': ['tactile_contact_not_detected',\n",
       "     'grip_force_too_low',\n",
       "     'object_slipped_from_gripper'],\n",
       "    'recovery_strategies': ['retry_grasp',\n",
       "     'increase_grip_force',\n",
       "     'realign_grasp_pose']},\n",
       "   'temporal_constraints': {'max_duration_sec': 1.5, 'urgency': 'high'}},\n",
       "  {'phase': 'Lift',\n",
       "   'symbol': '→[robot performs lift]',\n",
       "   'goal_state': {'object_lifted': True},\n",
       "   'preconditions': {'object_grasped': True,\n",
       "    'arm_vertical_clearance': True,\n",
       "    'no_obstacle_above': True},\n",
       "   'force_dynamics': {'contact': True,\n",
       "    'motion_type': 'linear',\n",
       "    'force_exerted': 'lift',\n",
       "    'force_profile': {'type': 'constant',\n",
       "     'expected_range_N': [10.0, 20.0],\n",
       "     'expected_range_Nm': None}},\n",
       "   'sensory_feedback': {'force_sensor_indicates_lift': True,\n",
       "    'arm_clearance_verified': True},\n",
       "   'failure_and_recovery': {'possible_failures': ['lift_force_too_low',\n",
       "     'object_unstable_during_lift',\n",
       "     'collision_detected_with_obstacle'],\n",
       "    'recovery_strategies': ['increase_lift_force',\n",
       "     'pause_and_stabilize',\n",
       "     'reposition_arm_clearance']},\n",
       "   'temporal_constraints': {'max_duration_sec': 3.0, 'urgency': 'high'}},\n",
       "  {'phase': 'Withdraw',\n",
       "   'symbol': '→[robot performs withdraw]',\n",
       "   'goal_state': {'object_carried': True},\n",
       "   'preconditions': {'object_stable': True,\n",
       "    'gripper_closed': True,\n",
       "    'arm_position_known': True},\n",
       "   'force_dynamics': {'contact': False,\n",
       "    'motion_type': 'linear',\n",
       "    'force_exerted': 'none',\n",
       "    'force_profile': {'type': 'constant',\n",
       "     'expected_range_N': [0.0, 0.0],\n",
       "     'expected_range_Nm': None}},\n",
       "   'sensory_feedback': {'object_stability_confirmed': True,\n",
       "    'gripper_state_verified': True},\n",
       "   'failure_and_recovery': {'possible_failures': ['object_unstable_during_withdrawal',\n",
       "     'gripper_state_not_verified',\n",
       "     'arm_position_misaligned'],\n",
       "    'recovery_strategies': ['recheck_object_stability',\n",
       "     'reposition_gripper_state',\n",
       "     'adjust_arm_position']},\n",
       "   'temporal_constraints': {'max_duration_sec': 1.5, 'urgency': 'low'}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Practice",
   "id": "6edb52faee07a044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(e2e_graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "875336a0f3609145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in e2e_graph.stream({\"instruction\" : 'pour the water from the mug into sink'}, subgraphs=True, config=config):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ],
   "id": "95c939165d0bb06e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_state = e2e_graph.invoke({\"instruction\" : 'pour the water from the mug into sink'}, config=config)",
   "id": "9888d0edbead189b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2fbc7b9cb5d297b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a3ff2ec4632d669"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
